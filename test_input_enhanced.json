{
  "input": {
    "workflow": {
      "1": {
        "inputs": {"image": "face_ref.png", "upload": "image"},
        "class_type": "LoadImage",
        "_meta": {"title": "Load Reference Face"}
      },
      "2": {
        "inputs": {"provider": "CPU"},
        "class_type": "InstantIDFaceAnalysis",
        "_meta": {"title": "InstantID Face Analysis"}
      },
      "3": {
        "inputs": {"ckpt_name": "lustifySDXLNSFW_ggwpV7.safetensors"},
        "class_type": "CheckpointLoaderSimple",
        "_meta": {"title": "Load Checkpoint"}
      },
      "4": {
        "inputs": {"instantid_file": "ip-adapter.bin"},
        "class_type": "InstantIDModelLoader",
        "_meta": {"title": "InstantID Model Loader"}
      },
      "5": {
        "inputs": {"control_net_name": "instantid-controlnet.safetensors"},
        "class_type": "ControlNetLoader",
        "_meta": {"title": "InstantID ControlNet"}
      },
      "6": {
        "inputs": {
          "text": "RAW photo, portrait of a woman in a red dress, golden hour sunlight, detailed face, stunning beauty, skin texture, skin pores, 85mm lens, cinematic depth of field, natural lighting, photorealistic, 8k",
          "clip": ["3", 1]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {"title": "Positive Prompt"}
      },
      "7": {
        "inputs": {
          "text": "(worst quality, low quality, blurry:1.2), (bad anatomy, bad proportions:1.1), (deformed face, ugly face), (deformed hands, bad hands, fused fingers), watermark, text",
          "clip": ["3", 1]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {"title": "Negative Prompt"}
      },
      "8": {
        "inputs": {"width": 832, "height": 1216, "batch_size": 1},
        "class_type": "EmptyLatentImage",
        "_meta": {"title": "Empty Latent"}
      },
      "20": {
        "inputs": {
          "preset": "FACEID PLUS V2",
          "model": ["3", 0]
        },
        "class_type": "IPAdapterUnifiedLoaderFaceID",
        "_meta": {"title": "IPAdapter FaceID Loader"}
      },
      "21": {
        "inputs": {
          "weight": 0.7,
          "weight_type": "linear",
          "start_at": 0.0,
          "end_at": 1.0,
          "image": ["1", 0],
          "model": ["20", 0],
          "ipadapter": ["20", 1]
        },
        "class_type": "IPAdapterFaceID",
        "_meta": {"title": "Apply IPAdapter FaceID"}
      },
      "9": {
        "inputs": {
          "instantid": ["4", 0],
          "insightface": ["2", 0],
          "control_net": ["5", 0],
          "image": ["1", 0],
          "model": ["21", 0],
          "positive": ["6", 0],
          "negative": ["7", 0],
          "weight": 0.8,
          "start_at": 0.0,
          "end_at": 1.0
        },
        "class_type": "ApplyInstantID",
        "_meta": {"title": "Apply InstantID"}
      },
      "10": {
        "inputs": {
          "seed": 42,
          "steps": 35,
          "cfg": 3.5,
          "sampler_name": "dpmpp_2m_sde",
          "scheduler": "karras",
          "denoise": 1,
          "model": ["9", 0],
          "positive": ["9", 1],
          "negative": ["9", 2],
          "latent_image": ["8", 0]
        },
        "class_type": "KSampler",
        "_meta": {"title": "KSampler"}
      },
      "11": {
        "inputs": {"samples": ["10", 0], "vae": ["3", 2]},
        "class_type": "VAEDecode",
        "_meta": {"title": "VAE Decode"}
      },
      "30": {
        "inputs": {"model_name": "bbox/face_yolov8m.pt"},
        "class_type": "UltralyticsDetectorProvider",
        "_meta": {"title": "Face Detector (YOLO)"}
      },
      "31": {
        "inputs": {
          "guide_size": 512,
          "guide_size_for": true,
          "max_size": 1024,
          "seed": 42,
          "steps": 20,
          "cfg": 3.5,
          "sampler_name": "dpmpp_2m_sde",
          "scheduler": "karras",
          "denoise": 0.35,
          "feather": 5,
          "noise_mask": true,
          "force_inpaint": true,
          "bbox_threshold": 0.5,
          "bbox_dilation": 10,
          "bbox_crop_factor": 3.0,
          "sam_detection_hint": "center-1",
          "sam_dilation": 0,
          "sam_threshold": 0.93,
          "sam_bbox_expansion": 0,
          "sam_mask_hint_threshold": 0.7,
          "sam_mask_hint_use_negative": "False",
          "drop_size": 10,
          "wildcard": "",
          "cycle": 1,
          "image": ["11", 0],
          "model": ["3", 0],
          "clip": ["3", 1],
          "vae": ["3", 2],
          "positive": ["6", 0],
          "negative": ["7", 0],
          "bbox_detector": ["30", 0]
        },
        "class_type": "FaceDetailer",
        "_meta": {"title": "FaceDetailer"}
      },
      "12": {
        "inputs": {"filename_prefix": "ComfyUI", "images": ["31", 0]},
        "class_type": "SaveImage",
        "_meta": {"title": "Save Image"}
      }
    },
    "images": [{"name": "face_ref.png", "image": "BASE64_FACE_IMAGE_HERE"}]
  }
}
